# The DBA Research Question Handbook
*A Practical Guide to Formulating Research Questions That Matter*

## Why Your Research Question Is Everything

Your research question isn't just the starting point of your dissertation—it's the blueprint for the entire project. Think of it like the foundation of a building. Get it wrong, and everything else becomes unstable. Get it right, and you have a clear path from problem to solution.

The DBA is fundamentally different from a PhD. While PhD students develop new theories, DBA candidates solve real business problems using existing theories as tools. Your research question needs to reflect this applied focus while maintaining scholarly rigor.

**The Bottom Line**: A well-crafted research question transforms a business headache into a solvable research problem that creates real impact.

## From Business Problem to Research Question

### Start With What's Keeping You Up at Night

Every DBA student enters their program with a "felt problem"—something that's been frustrating them in their professional life. Maybe it's:
- "Our best people keep leaving"
- "Digital transformation projects keep failing"  
- "We can't seem to innovate fast enough"

These statements are starting points, not research questions. They're symptoms that need diagnosis.

### Drill Down Using the "5 Whys"

Let's follow one example from symptom to specific problem:

**Felt Problem**: "Our employee turnover is killing us."

**Why #1**: Why is turnover so high?
*Because our high-potential employees are leaving for competitors.*

**Why #2**: Why are high-potential employees leaving?
*They say there's no clear path for advancement.*

**Why #3**: Why isn't there a clear advancement path?
*Our recent merger left us with two different career ladder systems that don't align.*

**Why #4**: Why weren't the career systems integrated?
*The merger team focused on financial and operational integration, not human capital.*

**Why #5**: Why was human capital deprioritized?
*Leadership underestimated how cultural misalignment would drive talent away.*

**Result**: We've moved from "turnover is high" to "post-merger human capital integration failures are causing high-potential talent attrition due to unclear advancement opportunities."

Now we have something specific and researchable.

### Connect Your Problem to Academic Literature

Once you've drilled down to a specific problem, you need to find the academic conversation it fits into. This is where you transform an organizational problem into a research problem by identifying what scholars call a "research gap."

**Quick Gap-Spotting Strategy**: Look at the "limitations" and "future research" sections of recent journal articles in your area. Authors literally tell you what hasn't been studied yet.

### Four Types of Research Gaps (With Business Examples)

**The Classic Gap**: Nobody has studied this yet
*Example*: "Very little research exists on how generative AI tools like ChatGPT are being integrated into strategic planning processes by C-suite executives."

**The Disagreement Gap**: Studies contradict each other  
*Example*: "Research on open-plan offices shows conflicting results—some studies find increased collaboration, others find decreased productivity. What explains these differences?"

**The Contextual Gap**: It's been studied, but not in your setting
*Example*: "Servant leadership has been extensively studied in healthcare and nonprofits, but barely examined in unionized construction environments."

**The Methodological Gap**: It's been studied one way, but not another
*Example*: "Customer satisfaction with airlines has been measured quantitatively, but we lack deep qualitative understanding of what 'service failure' actually feels like to business travelers."

## Matching Your Question Type to Your Research Method

The way you phrase your research question determines your methodology. This isn't optional—it's logical necessity.

### Decision Tree: What Kind of Question Are You Asking?

**If you're asking "How do people experience X?" → You need qualitative methods**
- Tools: Interviews, focus groups, case studies
- Analysis: Thematic analysis, coding

**If you're asking "How much?" or "How often?" → You need quantitative methods**
- Tools: Surveys, secondary data analysis  
- Analysis: Descriptive statistics, correlation

**If you're asking "What's the difference between Group A and Group B?" → You need comparative methods**
- Tools: Comparative surveys, quasi-experiments
- Analysis: t-tests, ANOVA

**If you're asking "Does X cause Y?" → You need experimental or quasi-experimental methods**
- Tools: Controlled trials, natural experiments, rigorous quasi-experiments
- Analysis: Regression, causal inference techniques

### Real Examples Across Business Disciplines

**Exploratory Question (Qualitative)**
*Marketing*: "How do Generation Z consumers experience brand authenticity on TikTok?"
*Why qualitative*: You're exploring subjective perceptions and experiences.

**Descriptive Question (Quantitative)**  
*Finance*: "What is the relationship between ESG scores and stock performance among S&P 500 companies?"
*Why quantitative*: You're measuring correlation between two variables.

**Comparative Question (Quantitative)**
*Management*: "What is the difference in employee retention rates between departments led by internally promoted versus externally hired managers?"
*Why quantitative*: You're comparing outcomes between two distinct groups.

**Causal Question (Experimental)**
*Operations*: "What is the effect of implementing agile project management, compared to waterfall methodology, on software development team productivity?"
*Why experimental*: You're testing whether one approach causes different outcomes than another.

## The PICO Framework: Your Question-Building Tool

PICO helps you build complete, precise questions. It's borrowed from medical research but works perfectly for business problems.

**P - Population**: Who are you studying?
**I - Intervention**: What action/strategy/change are you examining?  
**C - Comparison**: What are you comparing it to?
**O - Outcome**: What results are you measuring?

### PICO in Action: A Complete Example

**Business Problem**: New product launches keep missing revenue targets.

**Breaking it down with PICO**:
- **P** (Population): Cross-functional product development teams in consumer electronics firms
- **I** (Intervention): Agile development methodology  
- **C** (Comparison): Traditional waterfall methodology
- **O** (Outcome): On-time launch rates and first-year revenue achievement

**Final Question**: "For cross-functional product development teams in consumer electronics firms, what is the effect of agile development methodology, compared to waterfall methodology, on on-time launch rates and first-year revenue achievement?"

### When PICO Doesn't Fit: Enter SPIDER (For Qualitative Questions)

If you're asking "how" or "what is the experience of," PICO's focus on interventions doesn't work. Use SPIDER instead:

**S - Sample**: Who specifically are you talking to?
**P - Phenomenon**: What experience/process are you exploring?  
**I - Interest**: What aspects are you most curious about?
**D - Design**: How will you study it? (interviews, case study, etc.)
**E - Evaluation**: What insights are you hoping to gain?
**R - Research Type**: Qualitative, mixed-methods, etc.

**SPIDER Example**: "What are the lived experiences of psychological safety among mid-level managers in highly regulated financial services, and what leadership behaviors do they identify as fostering or inhibiting it?"

## The Refinement Process: From Rough Draft to Research-Ready

### Step 1: Brain Dump Your Ideas
Don't self-censor. Write down multiple versions of your question, even if they're messy:
- "Why are remote teams more productive?"
- "How does leadership style affect virtual team performance?"  
- "What's the difference between hybrid and fully remote work?"

### Step 2: Pick Your Best Option and Apply a Framework
Choose the most promising question and run it through PICO or SPIDER to add structure and completeness.

### Step 3: Eliminate All Vague Language
Every word in your final question must be specific and definable.

**Vague**: "What effect does social media have on people's minds?"
**Specific**: "What is the effect of daily Instagram use on self-reported body image among female university students aged 18-21?"

The second version defines the platform (Instagram), usage pattern (daily), population (female students, 18-21), and outcome (self-reported body image).

### Step 4: Apply the "So What?" Test
Can you clearly explain why anyone should care about the answer to your question? If you can't make a compelling case for relevance, keep refining.

### Step 5: Break Down Complex Questions into Sub-Questions

For dissertation-level complexity, you'll often need 3-4 sub-questions that build toward answering your main question.

**Main Question**: "How can a family-owned manufacturing firm implement digital transformation to enhance competitiveness?"

**Sub-Questions**:
1. "What are the firm's current digital capabilities compared to industry benchmarks?" (Baseline)
2. "What cultural barriers to technology adoption exist?" (Challenges)  
3. "What is the impact of piloting digital supply chain tools on inventory turnover?" (Testing solutions)
4. "What leadership competencies are needed for successful digital transformation?" (Implementation)

## The Final Check: FINER Criteria

Before you commit to your question, run it through this final quality check:

### Feasible
- Can you actually get the data you need?
- Do you have the skills for this type of analysis?
- Can you complete this in your program timeframe?
- Is it within your budget?

*Red flags*: Requiring access to CEO-level data when you're mid-management, needing advanced statistical techniques you've never used, studying 50 companies when you have access to 5.

### Interesting  
- Are YOU genuinely curious about the answer?
- Will other practitioners care about your findings?
- Does it connect to current academic debates?

*Red flags*: Picking a "safe" topic you're not passionate about, addressing problems only your specific company faces, ignoring what scholars are currently discussing.

### Novel
- Does it address a clear research gap?
- Will it add something new to knowledge?
- Have you checked that it hasn't already been answered?

*Red flags*: Restating well-established findings, missing obvious prior research, choosing questions that seem "too easy."

### Ethical
- Does your research respect participant privacy and safety?
- Are there conflicts of interest you need to manage?
- Will you need IRB approval, and can you get it?

*Red flags*: Studying your own direct reports, accessing confidential data without permission, research that could harm participants' careers.

### Relevant
- Does it address a significant business problem?
- Will your findings lead to actionable recommendations?
- Can it contribute to responsible management practices?

*Red flags*: Purely academic exercises with no practical application, research that only benefits one specific organization, studies that can't inform decision-making.

## Common Pitfalls and How to Avoid Them

### The "Boiling the Ocean" Problem
**What it looks like**: "How can companies improve performance?"
**Why it's bad**: Too broad to research meaningfully
**Fix**: Narrow to specific performance metrics, specific types of companies, specific interventions

### The "Consulting Project" Problem  
**What it looks like**: Questions that only matter to your specific organization
**Why it's bad**: Lacks scholarly contribution
**Fix**: Connect your organizational problem to broader theoretical frameworks and research gaps

### The "Methodology Mismatch" Problem
**What it looks like**: Asking "how do people experience X" but planning a survey
**Why it's bad**: Your methods can't answer your question  
**Fix**: Align your question wording with appropriate research methods

### The "Moving Target" Problem
**What it looks like**: Constantly changing your research question
**Why it's bad**: You never make progress on any single inquiry
**Fix**: Set a deadline for finalizing your question and stick to it

## Quick Reference: Question Templates by Type

### For Exploring Experiences (Qualitative)
"What are the lived experiences of [specific population] when [specific situation/phenomenon], and what [specific factors] do they identify as [facilitating/hindering] [specific outcome]?"

### For Measuring Relationships (Quantitative)  
"What is the relationship between [specific variable X] and [specific variable Y] among [specific population] in [specific context]?"

### For Comparing Groups (Quantitative)
"What is the difference in [specific outcome] between [Group A] and [Group B] among [specific population] in [specific context]?"

### For Testing Interventions (Experimental)
"What is the effect of [specific intervention], compared to [specific alternative], on [specific outcome] among [specific population] in [specific context]?"

## Your Research Question Roadmap

1. **Identify your felt problem** (What's bugging you professionally?)
2. **Drill down with 5 Whys** (Get specific about root causes)
3. **Find the research gap** (What haven't scholars studied yet?)
4. **Choose your question type** (Exploratory, descriptive, comparative, or causal?)
5. **Apply PICO or SPIDER** (Structure your question completely)
6. **Refine for precision** (Eliminate all vague language)
7. **Test with FINER criteria** (Is it feasible, interesting, novel, ethical, relevant?)
8. **Develop sub-questions if needed** (Break complex questions into parts)

Remember: Your research question is your dissertation's GPS. It tells you exactly where you're going and how to get there. Invest the time to get it right, and everything else becomes much clearer.

The best DBA research questions solve real business problems while contributing to scholarly knowledge. They're specific enough to research rigorously but significant enough to matter beyond your own organization. When you've crafted a question that passes these tests, you're ready to change how business gets done.
